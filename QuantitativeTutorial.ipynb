{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PK_6800_Day2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lwschm/quantitative_tutorial/blob/main/QuantitativeTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 2: Code used during lecture and lab assignment"
      ],
      "metadata": {
        "id": "71QCGinKTAAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "- The notebook combines 'code used during lecture' with the 'Day 2 lab' assignment (see further down)\n",
        "- The lab assignment can be done largely by copying/paste/modification of the code used during the lecture\n",
        "- Please add answers/discussion/comments to the notebook as comments or text box. Do not create another file in addition.\n",
        "- When you are done with your assignment, save the notebook in drive and add your last name to the name of the file\n",
        "- Upload your final notebook (with your name appended) to https://uni-bonn.sciebo.de/s/fnkgjhNbKuAeI0K by September 30th. The password for access is the same as before (sent via email)\n",
        "\n"
      ],
      "metadata": {
        "id": "UBjm-4D-Tg-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code used during lecture"
      ],
      "metadata": {
        "id": "sINvJ4ugbKhz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn import tree\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "xn9LO_jCSar8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Set the numpy random seed\n",
        "np.random.seed(100)"
      ],
      "outputs": [],
      "metadata": {
        "id": "pHtbUP2Uf_pO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Download data\n",
        "!wget -nc https://ilr-ml-course.eu-central-1.linodeobjects.com/brazil_all_data_v2.gz"
      ],
      "outputs": [],
      "metadata": {
        "id": "gWJ6IasttlnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load data with pandas into a dataframe \n",
        "df = pd.read_parquet('brazil_all_data_v2.gz')"
      ],
      "outputs": [],
      "metadata": {
        "id": "d8QMuJ64tnh9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define binary variable for deforestration in 2018\n",
        "df['D_defor_2018'] = df['defor_2018']>0\n",
        "Y_all = df['D_defor_2018']"
      ],
      "outputs": [],
      "metadata": {
        "id": "DN3evVUDoiVx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define a list of features names (explantory variables)\n",
        "lstX = [\n",
        "  'wdpa_2017',\n",
        "  'population_2015',\n",
        "  'chirps_2017',\n",
        "  'defor_2017',\n",
        "  'maize',\n",
        "  'soy',\n",
        "  'sugarcane',\n",
        "  'perc_treecover',\n",
        "  'perm_water',\n",
        "  'travel_min',\n",
        "  'cropland',\n",
        "  'mean_elev',\n",
        "  'sd_elev',\n",
        "  'near_road',\n",
        "  'defor_2017_lag_1st_order',\n",
        "  'wdpa_2017_lag_1st_order',\n",
        "  'chirps_2017_lag_1st_order',\n",
        "  'population_2015_lag_1st_order',\n",
        "  'maize_lag_1st_order',\n",
        "  'soy_lag_1st_order',\n",
        "  'sugarcane_lag_1st_order',\n",
        "  'perc_treecover_lag_1st_order',\n",
        "  'perm_water_lag_1st_order',\n",
        "  'travel_min_lag_1st_order',\n",
        "  'cropland_lag_1st_order',\n",
        "  'mean_elev_lag_1st_order',\n",
        "  'sd_elev_lag_1st_order',\n",
        "  'near_road_lag_1st_order',\n",
        " ]\n",
        "\n",
        "# Get the explanatory Variables\n",
        "X_all =  df.loc[:,lstX]"
      ],
      "outputs": [],
      "metadata": {
        "id": "z2ZGZoInoHAV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Split the data into train and test data using sklearn train_test_split object\n",
        "#   (see: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "\n",
        "#   Note: This randomly split the data in 80% train and 20% test data\n",
        "X_train_raw, X_test_raw, Y_train, Y_test = train_test_split(X_all, Y_all, test_size = 0.2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yZ5TrMhZ2pxs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Scale data to 0-1 range using sklearn MinMaxScalar object \n",
        "# (see: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) \n",
        "scaler = MinMaxScaler()\n",
        "# Use only the train data to fit the MinMaxScalar \n",
        "scaler.fit(X_train_raw)\n",
        "\n",
        "# Apply the MinMax transformation to the train and test data \n",
        "X_train = scaler.transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)\n",
        "# Note the depended variable does not need to be scaled as it is a binary variable anyway"
      ],
      "outputs": [],
      "metadata": {
        "id": "l9ijNiMD2nH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run logit on deforestation binary variable"
      ],
      "metadata": {
        "id": "hRd3KIDXp152"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Fit a logistic regression model using sklearn \n",
        "# (see: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "\n",
        "# Create the model object\n",
        "modelLg = LogisticRegression(random_state=0,penalty='none',fit_intercept=True,max_iter=1000)\n",
        "# Fit the model using the training data\n",
        "modelLg.fit(X_train, Y_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "dSjHfg6PmxDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Define a function that prints the model statistics.\n",
        "# We will use the function below to always get the same model stats for each of\n",
        "# the model the we will estimate below.\n",
        "def printOutput(mod,X_train,Y_train,X_test,Y_test):\n",
        "  # view results\n",
        "  print('Score in train', mod.score(X_train, Y_train))\n",
        "  print('Score in test', mod.score(X_test, Y_test))\n",
        "\n",
        "  Y_test_had_Tree = mod.predict(X_test)\n",
        "\n",
        "  print('\\nConfusion Matrix')\n",
        "  print(pd.DataFrame(confusion_matrix(Y_test, Y_test_had_Tree),\n",
        "            index=pd.MultiIndex.from_arrays([['actual','actual'], ['False','True']]),\n",
        "            columns=pd.MultiIndex.from_arrays([['predicted','predicted'], ['False','True']])))"
      ],
      "outputs": [],
      "metadata": {
        "id": "UOuCMR7V-_Ta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Use the function to print the model statistics for our logit model \n",
        "printOutput(modelLg,X_train,Y_train,X_test,Y_test)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "\n",
        "# Get the predicted probabiltities \n",
        "Y_score = modelLg.decision_function(X_test)\n",
        "\n",
        "# Get true positive and false positive rate\n",
        "# See: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
        "fpr_Lg, tpr_Lg, _ = roc_curve(Y_test, Y_score)\n",
        "\n",
        "# Get the Area under the cureve (AUC)\n",
        "# See: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n",
        "roc_auc_Lg = auc(fpr_Lg, tpr_Lg)\n",
        "\n",
        "print('\\nROC AUC', roc_auc_Lg)"
      ],
      "outputs": [],
      "metadata": {
        "id": "toJ0q4YvoEs9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr_Lg, tpr_Lg, color='darkorange',\n",
        "         lw=lw, label='Logistic ROC curve (area = %0.2f' % roc_auc_Lg)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "dR7Zu0K_6PKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run a decision tree using the same specification"
      ],
      "metadata": {
        "id": "mWCB8SaR1Qlm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Fit a decision tree using sklearn\n",
        "# (see https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
        "\n",
        "# Define a model object\n",
        "modelTree = tree.DecisionTreeClassifier()\n",
        "# Fit the model\n",
        "modelTree = modelTree.fit(X_train, Y_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9C2g9xH8qFig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Use the function to print the model statistics for our tree model \n",
        "printOutput(modelTree,X_train,Y_train,X_test,Y_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "X45zdwZblFDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the same model using  a random forest"
      ],
      "metadata": {
        "id": "SUu8fjY-2P6m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# run a random forest using sklearn and default hyperparameters (note, this will take a few minutes)\n",
        "# (see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create model object\n",
        "modelForest = RandomForestClassifier()\n",
        "# Fit model\n",
        "modelForest = modelForest.fit(X_train, Y_train)"
      ],
      "outputs": [],
      "metadata": {
        "id": "HOeVa-8z2KNL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Print model output stats\n",
        "printOutput(modelForest,X_train,Y_train,X_test,Y_test)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "OvZPmhHH96Yv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ====================\n",
        "# Discuss in the group\n",
        "# ====================\n",
        "# What do you conclude from the model outcome. Is this a \n",
        "# useful model. Compare the results to the logit outcomes. "
      ],
      "outputs": [],
      "metadata": {
        "id": "GyMYFqribubG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot ROC curve \n",
        "# Get the predicted probabiltities \n",
        "Y_scoreRF = modelForest.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Get true positive and false positive rate\n",
        "fpr_RF, tpr_RF, _ = roc_curve(Y_test, Y_scoreRF)\n",
        "\n",
        "# Get the Area under the cureve (AUC)\n",
        "roc_auc_RF = auc(fpr_RF, tpr_RF)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr_RF, tpr_RF, \n",
        "         lw=lw, label='RF ROC curve (area = %0.2f' % roc_auc_RF)\n",
        "plt.plot(fpr_Lg, tpr_Lg, \n",
        "         lw=lw, label='Logistic ROC curve (area = %0.2f' % roc_auc_Lg)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "1lqaLHLVdvKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the results"
      ],
      "metadata": {
        "id": "bh5EZajJsA8N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Generate a feature importance graph for the forest\n",
        "# Adjusted based on  https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "\n",
        "importances = modelForest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in modelForest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "\n",
        "for f in range(X_train.shape[1]):\n",
        "    print(\"%d. %s (%f)\" % (f + 1, lstX[f], importances[indices[f]]))\n",
        "\n",
        "# Plot the impurity-based feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices],\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "# plt.xticks(range(X_train.shape[1]), indices)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "QeXTB7BZsgc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab"
      ],
      "metadata": {
        "id": "IoA_xEY6rLjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lab today will have you predict deforestation using both a random forest and XGboost models"
      ],
      "metadata": {
        "id": "faiHfDS04JDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# In the lecture part we have run a Random Forest that heavily \n",
        "# overfitted the training data. Adjust a hyperparamter \n",
        "# and see if you can train a model that does not overfit.\n",
        "\n",
        "# Hint: Vary the parameter max_depth or min_samples_split\n",
        "\n",
        "# Sklearn documentation on RF:\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba\n",
        "\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "modelForest = ...\n",
        "\n",
        "# Fit model\n",
        "...\n",
        "\n",
        "#  Print model stats output\n",
        "printOutput(...)"
      ],
      "outputs": [],
      "metadata": {
        "id": "dfVYG7QSay2e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Now run an XGBoost model for the same task \n",
        "import xgboost as xgb\n",
        "\n",
        "# Hint: 1) Look at one of the tutorial on XGB on how to specify and run the model\n",
        "#          (e.g. https://hackernoon.com/want-a-complete-guide-for-xgboost-model-in-python-using-scikit-learn-sc11f31bq) \n",
        "#       2) You do not need to adjust hypterparamter here. The default paramters\n",
        "#          should be fine here.\n",
        "\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "# Specify model \n",
        "model_xgb = ...\n",
        "\n",
        "\n",
        "# Fit model to data\n",
        "model_xgb ...\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "_l6voaZ5SasI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Print the model stats of you XGB model using the function from above\n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "...\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "1_0NfwuZAQF1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Compare to the outcome of the other model \n",
        "# (not need to change anything here) \n",
        "print('\\n--- Logistic')\n",
        "printOutput(modelLg,X_train,Y_train,X_test,Y_test)\n",
        "\n",
        "print('\\n--- Tree')\n",
        "printOutput(modelTree,X_train,Y_train,X_test,Y_test)\n",
        "\n",
        "print('\\n--- Forest')\n",
        "printOutput(modelForest,X_train,Y_train,X_test,Y_test)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "uv_0pQBtApns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Write a couple of sentences on what you see in your models, which you \n",
        "# believe are performing better and why\n",
        "# ================\n",
        "# Your answer here\n",
        "# ================\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "3RwF-b5NcE2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot an ROC corve for the Logit, Random Forest and XGB model \n",
        "\n",
        "# Hint: Check what we have done above... \n",
        "# ==============\n",
        "# Your code here\n",
        "# ==============\n",
        "# Get the predicted probabiltities \n",
        "Y_scoreXG = ...\n",
        "\n",
        "# Get true positive and false positive rate\n",
        "fpr_XG, tpr_XG, _ = ...\n",
        "\n",
        "# Get the Area under the cureve (AUC)\n",
        "roc_auc_XG = ...\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "7wbPaM6uewwX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Plot the figure (not need to change anything here)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "\n",
        "plt.plot(fpr_XG, tpr_XG, \n",
        "         lw=lw, label='XG ROC curve (area = %0.2f' % roc_auc_XG)\n",
        "\n",
        "plt.plot(fpr_Lg, tpr_Lg, \n",
        "         lw=lw, label='Logistic ROC curve (area = %0.2f' % roc_auc_Lg)\n",
        "\n",
        "plt.plot(fpr_RF, tpr_RF, \n",
        "         lw=lw, label='RF ROC curve (area = %0.2f' % roc_auc_RF)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "vpXpt0TUhOWr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# In one or two sentences, discuss what the ROC curves are telling you \n",
        "# ================\n",
        "# Your answer here\n",
        "# ================\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "xWmorRE8cwUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional Tasks"
      ],
      "metadata": {
        "id": "vw2LzA78eCjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Generate your model's prediction errors and explore them - comparing different subsets of your data (e.g. protected areas vs others)"
      ],
      "metadata": {
        "id": "KVItUaaw4T4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "NlZwcBqV4EzK"
      }
    }
  ]
}